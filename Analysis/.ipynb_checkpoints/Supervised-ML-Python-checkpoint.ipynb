{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a306cd3-a4d0-42d2-a21a-d1aa369644c1",
   "metadata": {},
   "source": [
    "# Northern Michigan Snowfall Prediction using Machine Learning Models \n",
    "### Or:  If a Decision Tree Falls in the Snow in a Random Forest, Will Anyone Hear It?\n",
    "\n",
    "\n",
    "\n",
    "#### Supervised Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959923d-d8f9-4bd1-a2e0-eb8fb3ecd411",
   "metadata": {},
   "source": [
    "---\n",
    "<p style=\"text-align: center \">\n",
    "  <img  src=\"../Media/snowmobile-I-500.png\" width=\"600\" height = \"300\" alt=\"I 500 snowmobile race\">\n",
    "</p>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb70b2-657b-4977-97bb-e718fbdde4a2",
   "metadata": {},
   "source": [
    "### Table of Contents <a class=\"anchor\" id=\"soo_toc\"></a>\n",
    "\n",
    "* [Table of Contents](#soo_toc)\n",
    "    * [Page 1 - Introduction](#soo_page_1)\n",
    "    * [Page 2 - Importation of Libraries and Reading in the Data](#soo_page_2)\n",
    "    * [Page 3 - Feature Engineering](#soo_page_3)\n",
    "    * [Page 4 - Train Test Groups Split for Supervised Machine Learning](#soo_page_4)\n",
    "    * [Page 5 - Linear Regression Model](#soo_page_5)\n",
    "    * [Page 6 - K-Folds Cross Validation](#soo_page_6)\n",
    "    * [Page 7 - Decision Tree Regressor Model](#soo_page_7)\n",
    "    * [Page 8 - A Whole Random Forest](#soo_page_8)\n",
    "    * [Page 9 - Conclusions and Findings, Future Growth Possibilities](#soo_page_9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065961d9-3453-4bab-ae5e-2739b7194d00",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 1 - Introduction<a class=\"anchor\" id=\"soo_page_1\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4ff0c-9dac-41b2-9853-e9383231de72",
   "metadata": {},
   "source": [
    "How accurately can I create a model that can predict whether there will be snowfall on any given day, or just Christmas Day in Sault Ste. Marie, Michigan? \n",
    "Sault Ste. Marie is located at the top of the Upper Peninsula, in Northern Michigan. It comes from the French, so it's pronounced \"Soo Saint Marie, \" or \"the Soo,\" for short. The city's name comes from Saults de Sainte-Marie, archaic French for \"Saint Mary's Falls\", a reference to the rapids of Saint Marys River. \n",
    "\n",
    "Pristine lakes and waterfalls, my favorite people in the world and abundant trees make this one of my favorite places on Earth. Given it's north of the 45th parallel, it's not the warmest year-round. There can be snow on the ground for some six months of the year, lasting from late October with the last bits finally disappearing around the beginning of May. So it's not a stretch to predict if there will be snow on the ground in December - but will there be a new blanket of fresh white snow to wake up to on Christmas Day?  That may take a bit more finesse to figure out. \n",
    "\n",
    "We gathered datasets from weather stations in and near Sault Ste. Marie in order to have a more robust dataset. Links to the data from the National Centers for Environmental Information/ NOAA can be found [here](https://www.ncei.noaa.gov/access/past-weather/49783).\n",
    "There is a single dataset from a weather station at Sanderson Field in this study.  A study of all of the area weather station data will be done in a separate notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddd700-d76a-4965-8297-572b494a4832",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 2 - Importation of Libraries and Reading in the Data <a class=\"anchor\" id=\"soo_page_2\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a0804a-050a-4ff3-aba8-f38e99493e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier #can handle NANs\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor #can handle NANs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8732ad9-9107-4f80-9cd9-b41e0c361578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d3e08-5b5a-476c-8f40-0023f7e21d8b",
   "metadata": {},
   "source": [
    "Dates can be a little tricky to format for machine learning, so initially, I'm going to see if we can predict snowfall for any given day. Later, I'll narrow down the dates to just Christmas and compare the two. Speaking of dates, this dataset begins January 1, 1948 and runs to November 28, 2022.  Data was collected from Sanderson Air Field in Sault Ste. Marie and downloaded from [this link](https://www.ncei.noaa.gov/access/past-weather/49783). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc467842-e453-4af4-b147-d4a7934bf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = pd.read_csv(r\"..\\DATA\\Sault-Weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03668733-43de-49fe-96a1-35f3301b0cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>SnowDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  AvgTemp  MaxTemp  MinTemp  Precip  SnowFall  SnowDepth\n",
       "0  1/1/1948      NaN     19.0      2.0    0.00       0.0       12.0\n",
       "1  1/2/1948      NaN     33.0     11.0    0.00       0.0       11.0\n",
       "2  1/3/1948      NaN     27.0      9.0    0.00       0.0       10.0\n",
       "3  1/4/1948      NaN     31.0     22.0    0.17       3.4       14.0\n",
       "4  1/5/1948      NaN     30.0     23.0    0.01       0.3       13.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404babc-3616-4cf2-b58f-4b4108c71dce",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 3 - Feature Engineering <a class=\"anchor\" id=\"soo_page_3\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "79db9b5b-5210-45ed-9a76-3837c1ea7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = snow.drop(['AvgTemp', 'Date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2fd5e949-9f1e-4c8f-908f-ebd0090ecd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>SnowDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxTemp  MinTemp  Precip  Snowfall  SnowDepth\n",
       "0     19.0      2.0    0.00       0.0       12.0\n",
       "1     33.0     11.0    0.00       0.0       11.0\n",
       "2     27.0      9.0    0.00       0.0       10.0\n",
       "3     31.0     22.0    0.17       3.4       14.0\n",
       "4     30.0     23.0    0.01       0.3       13.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "968f841a-9445-4f1e-ba39-27d5af4fdb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27361"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "668c4e16-b920-4941-829f-4dda52b4f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164166"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27361 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d3d5dc4-7a9f-4762-ae78-95a2d43489c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxTemp       23\n",
      "MinTemp      204\n",
      "Precip         2\n",
      "Snowfall     660\n",
      "SnowDepth    663\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(snow.isna().sum()) #number of NAs in each column - note these NAs may be in different rows. For instance, an NA in a particular row in one column may not have more NAs across the same row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "32e19d4b-4d97-4b38-b449-709388a9d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552\n"
     ]
    }
   ],
   "source": [
    "print(snow.isna().sum().sum()) #total number of NAs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df30f52f-ee7f-4d01-8e5d-4ded72f793c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009453845497849738"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1552/164166 # = percentage of NAN cells in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09503b-a142-4208-8766-74dba7fd48e1",
   "metadata": {},
   "source": [
    ".9 % of overall cells in dataset are null values, so it's safe to just drop them. It won't affect results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3a3664c-aefc-4a13-a641-941c037121b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24952, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see how many rows are present before dropping NAs - \n",
    "snow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3127290d-01f1-41f4-8b83-a4b0d9d035c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = snow.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8352d0f-3082-43ce-b333-f8b55a39f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see how many rows are lost after dropping NAs - \n",
    "snow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353fe12-da35-48a3-835f-b1a369ab7e32",
   "metadata": {},
   "source": [
    "Keeping all values in the Snowfall column that are not equal to zero. In other words, we're removing the zeroes for when snowfall was recorded. For the vast majority, the zeroes occur during the spring, summer and fall months (which are six months of the year). Later, when graphing the linear regression, we found that all of the zeroes skewed the distribution. More on that below. \n",
    "However, removing the days it doesn't snow removes the chance for the model to learn what it takes to \"not snow.\" learns from the absence of conditions to produce snow. Something to consider. \"isn't learning from its mistakes.\"  check boosting - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce0bfda8-f492-4efb-8cb9-6000f73d01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = snow[snow['Snowfall'] != 0   ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089712e-00ec-46ac-adf0-62ef0ea5c355",
   "metadata": {},
   "source": [
    "After removing the zeroes, we removed other outliers, three standard deviations on each side of the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "feb53913-ca73-4467-9c7a-37c0bb2e1e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>SnowDepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxTemp  MinTemp  Precip  Snowfall  SnowDepth\n",
       "0     19.0      2.0    0.00       0.0       12.0\n",
       "1     33.0     11.0    0.00       0.0       11.0\n",
       "2     27.0      9.0    0.00       0.0       10.0\n",
       "4     30.0     23.0    0.01       0.3       13.0\n",
       "5     31.0     22.0    0.09       2.1       14.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove outliers.  Absolute value of the standard dev from z score, on each value in each column (six sigma)\n",
    "snow = snow[(np.abs(stats.zscore(snow)) < 3).all(axis=1)]\n",
    "snow.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2ed0c8b-ed04-4dab-882f-9ba666cf7f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxTemp     -12.0\n",
       "MinTemp     -36.0\n",
       "Precip        0.0\n",
       "Snowfall      0.0\n",
       "SnowDepth     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking now to see if zeroes remain\n",
    "\n",
    "snow.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4aa077f-888d-4982-86e7-083a897d151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing high outliers, from extreme snow events in 1972 and 1995. We're keeping all values less than 40 inches of snowfall. \n",
    "\n",
    "snow = snow[snow['Snowfall'] < 40 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddab986-9102-448d-9efc-c2cdc5a64176",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 4 - Train Test Groups Split for Supervised Machine Learning<a class=\"anchor\" id=\"soo_page_4\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0c225b3-41ef-4b37-9b8d-a44fd363585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y consists of the target variable, or what I'm trying to predict. X is the group of variables that will be used to learn how to predict the y variable - or snowfall.\n",
    "\n",
    "x = snow[['MaxTemp', 'MinTemp', 'Precip', 'SnowDepth']]\n",
    "y = snow['Snowfall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f84481-d23b-4f9f-8ccc-a5151734f9c7",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "One of the key things that separates machine learning from statistics is that machine learning utilizes the concept of \"train test split.\" In statistics, you typically run your analysis on all the data you have available. In machine learning, you split your data in half, and reserve the first chunk for training the model, and the second half for testing the model. How big should a \"chunk\" be? Typically you want more data to be used for training than for testing. 80/20, 70/30, and 60/40 splits are all acceptable.\n",
    "\n",
    "\n",
    "You will utilize the train_test_split() function from sklearn to split your data. You will end up with four data sets at the end:\n",
    "\n",
    "\n",
    "* x_train\n",
    "* x_test\n",
    "* y_train\n",
    "* y_test\n",
    "\n",
    "There will be one training dataset and one testing dataset each for x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1163f14-4138-495c-96e9-b72f6ce83813",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .25)\n",
    "\n",
    "#reduced to 25/75 split to give more opportunity to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1028445e-4bcf-4cfd-b98e-fd18c2d51a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4397, 4) (4397,)\n",
      "(1466, 4) (1466,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bafc90-2eec-439f-aa93-1db1da2e1fd0",
   "metadata": {},
   "source": [
    "This is showing that in the training datasets, there are 4397 rows and 4 columns, and in the testing dataset, there are 1,466 rows and 4 columns. So you can see how the training and testing data is broken up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b486461-f8e8-4dd1-bb6c-01274ea96d2b",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 5 - Linear Regression Model <a class=\"anchor\" id=\"soo_page_5\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63462c1b-7a16-40d0-af22-04c0d2d88350",
   "metadata": {},
   "source": [
    "#### Creating a linear Regression Model\n",
    "\n",
    "Any time one hears the word regression, it means there is something being predicted. A linear regression is a numberic value, and a logistic regression is a categorical variable that's being predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b28ab08e-5042-42db-b8da-866fcfc2ba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression() \n",
    "lm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85d2e7-420a-4ce5-a5ab-11a83945242c",
   "metadata": {},
   "source": [
    "Model is created, now I can examine its predictions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c66e76b-7619-40a8-b9b5-7cd026a7c1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66998241, 0.59969743, 2.19733097, ..., 1.27423835, 0.25120157,\n",
       "       0.51666162])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lm.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7fe86-1b50-4cac-b7c6-229e1475b9eb",
   "metadata": {},
   "source": [
    "This information is not super useful by itself, but plotting it gives us a better idea of how accurate our predictions (and thus our model) is. The straighter the line, the better the model fit. We'll make a scatterplot with the plt.scatter() function, graphing the y_test data against the predictions from our training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72b068ff-50de-484a-a3d2-30376cf5a8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ad4135d2d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbiUlEQVR4nO3dbXBcV3kH8P+j9YasHRopE00mXuLYdBh5MCYR1UCmZpgkvAhInKguJaTQSWk77gdoSWhV7JKpnRbGnoqX8IFhxg1p6SQNJokRzpipYbApLUMykSMF4TgqlBcnaycRQxTA3sQr6emH3Stfre7b3nt37zl3/7+ZjKWr1b3naifPPfuc55wjqgoiIrJPT9YNICKieBjAiYgsxQBORGQpBnAiIksxgBMRWWpVJy926aWX6vr16zt5SSIi6x07duyXqtrffLyjAXz9+vWYmJjo5CWJiKwnIr/wOs4UChGRpRjAiYgsxQBORGQpBnAiIksxgBMRWaqjVShpGZ+sYOzwDE7NVbG2t4TR4QGMDJazbhYRUUdZF8DHJyvYeWAa1doCAKAyV8XOA9MAwCBORF3FuhTK2OGZpeDtqNYWMHZ4JqMWERFlw7oAfmqu2tJxIqK8si6Ar+0ttXSciCivrAvgo8MDKBULy46VigWMDg9k1CIiIm/jkxVs2XsEG3Ycwpa9RzA+WUn1/NYNYjoDlaxCISKTdaLgwroADtRvngGbiEwWVHCRVvyyLoVCRGSDThRcMIATEbVBJwouGMCJiNqgEwUXVubAiYhM14mCCwZwIqI2aXfBBVMoRESWYgAnIrIUAzgRkaUYwImILMUATkRkKQZwIiJLMYATEVkqNICLyL0i8oKI/Mh17BIR+baI/Ljxb197m0lERM2i9MD/DcC7m47tAPAdVX0dgO80viciog4KnYmpqt8TkfVNh28GcG3j668A+C6AT6TZMKI4xicrXCueukbcqfSXqerpxtfPAbjM74Uish3AdgBYt25dzMsRhevEAvpEJkk8iKmqCkADfr5PVYdUdai/vz/p5Yh8BS2gT5RHcQP48yJyOQA0/n0hvSYRxdOJBfSJTBI3gB8EcFvj69sAfCOd5hDF14kF9IlMEqWM8AEAPwAwICLPisifA9gL4J0i8mMA72h8T5SpTiygT2SSKFUot/r86O0pt4UokU4soE9kEm7oQLnS7gX0iUzCqfRERJZiACcishQDOBGRpRjAiYgsxQBORGQpBnAiIksxgBMRWYoBnIjIUgzgRESWYgAnIrIUAzgRkaUYwImILMUATkRkKQZwIiJLMYATEVmKAZyIyFIM4ERElmIAJyKyFAM4EZGlGMCJiCzFAE5EZCkGcCIiS61K8ssicgeAvwCgAKYBfFhVX06jYWHGJysYOzyDU3NVrO0tYXR4ACOD5U5cmojICLF74CJSBvDXAIZU9Q0ACgA+kFbDgoxPVrDzwDQqc1UogMpcFTsPTGN8stKJyxMRGSFRD7zx+yURqQFYDeBU8iaFGzs8g2ptYdmxam0BY4dnWuqFsxdPRDaL3QNX1QqAzwA4CeA0gJdU9VvNrxOR7SIyISITs7Oz8Vvqcmqu2tJxL+zFE5HtkqRQ+gDcDGADgLUA1ojIh5pfp6r7VHVIVYf6+/vjt9RlbW+ppeNegnrxREQ2SFKF8g4AP1PVWVWtATgA4PfTaVaw0eEBlIqFZcdKxQJGhwcinyONXjwRUZaSBPCTAK4RkdUiIgDeDuBEOs0KNjJYxp5tm1HuLUEAlHtL2LNtc0v56zR68UREWYo9iKmqj4nIQwCeADAPYBLAvrQaFmZksJxowHF0eAA7D0wvS6O02ovvFhzsJTJToioUVd0FYFdKbekoJwAxMAVzBnudB50z2AuAfyuijCUtI7Ra0l58N0irZJOI0sep9BSIg71E5mIAp0Ac7CUyV24C+PhkBVv2HsGGHYewZe8RTshJSRolm0TUHrnIgXOgrX042EtkrlwEcA60tRcHe4nMlIsUCgfaiKgb5SKAc6CNiLpRLgI4B9qIqBvlIgfOgTYi6ka5COAAB9qIqPvkIoVCRNSNGMCJiCyVmxSKCbjsKhF1EgN4SjgblIg6jSmUlHCPTSLqNAbwlHA2KBF1GgN4SjgblIg6jQE8JZwNSkSdxkHMlHA2KBF1GgN4ijgblIg6iSkUIiJLsQduEU4UIiI3BnBLdNNEIT6oiKJJFMBFpBfAPQDeAEAB/Jmq/iCFdlGTNLeNixIgswqi3fSgIkoqaQ78CwD+U1U3ArgKwInkTSIvaU0UcgJkZa4KxfkAOT5Zaek17cIZrUTRxQ7gInIxgLcB+DIAqOo5VZ1LqV1GGZ+sYMveI9iw4xC27D3SkUDWLK2JQlECZJZBlDNaiaJL0gPfAGAWwL+KyKSI3CMia5pfJCLbRWRCRCZmZ2cTXC4bWfZG3dKaKOQXCCuu41kGUc5oJYouSQBfBeBNAL6kqoMAzgDY0fwiVd2nqkOqOtTf35/gctkw5SP9yGAZe7ZtRrm3BAFQ7i1hz7bNLeeF/QKhAEsPpSyDKGe0EkWXZBDzWQDPqupjje8fgkcAt51JH+nTmCg0OjyAO/ZPQZuOK7A0IDo6PLBsIBHoXBDljFai6GIHcFV9TkSeEZEBVZ0B8HYAT6XXNDOs7S0tSy+4j9toZLCM2/dPef7MeShlHUQ5o5UomqR14H8F4H4RuQDATwF8OHmTzJJlb7RdyhEeSgyiROZLVEaoqlON/PYbVXVEVV9Mq2GmSCv3bBLmmYnygTMxI8hbbzTrFAkRpcPqAM4p1/Hw70aUD6LaXI/QPkNDQzoxMZHKuZqnXAP1NIDt6Y12Gp+s4K5HjuPFs7UVP+tbXcSurZv4tyMykIgcU9Wh5uPWLidrSn22LZwHnlfwBoAXz9YymaBERPFZm0IxqT7bBl4PvGZxF8cKw5QNUXtYG8DzVp/dblEfbF5/07i8UjZcXZAoPdamUFothctiQSoTFsFyRH2wuafUJxGUsmGqiygd1vbAnd7b7oPHMVetB4kLi97PoyzWmPa75sQvfoWjT892PJ3gNSHJi3tKfRJhKRumuoiSs7YH7nhlfnHpa7+BuCwGPP2uef+jJzNZ2dBrQpKfNIJr2DmY6iJKztoeOBB9l5osBjz9zt1ctJn2wGHQgGHzhKQte4/EHkcIG5j0G6MAOOuTKC1W98CjBuYslkdt5dxpPUhaXbs87pT6KNfxOjcA9JaKrNUnSonVATxqYI4SqOIOOPr9ntc1pcX7aFWrqaKgdV6C/h5RruN17rtvuRpTu97F4E2UEqtTKH4rBV63sR9b9h5Z9vF+z7bNvh/54w5yRvk99zWv29iPh49VEq9s6Je+iJMq8lrnJey+ol4nb2vIEJnG6gAeJUg6wWfPts34/o7rPc8Td8f3sN/zCmBDV16SaFJLUHBNqzY+7L5Yg09kBqsDOOA9MNdqMA7aJ7K5J++kF8YOz/gO0oX1eIHzDx0n7eDXtube9tlz8773l9ba5WE97DyukU5kI+sDeLM4aQS/HqXg/MxEdx13cxrE63x+gnrQQPinCT+n5qqpLRMb1sPmcrREZrB2NcJmYb3icm/JN4XitbKhYGXJHwAURLAQ8DcLWxHRr3Svt1TEK/OLkdrgJej+WsWVHonMkrvVCN3cZW1ewj7ee1VM+AXOoOAdZbcev08Cc9Xail59K4/WM6/MpzYhKI+7EBHlkfEplCgr2QVN2y5H/HgfdZKLXw88ag84aIJLK9ZcUMCZc+fvea5aS3V5AFaQEJnP6B541Ikpfr1aAfD9HdfHCkR+teO3vuWKFceLPYKz5+Yj1ZD7nbdvdbGl9rmDt6O5FjuoltukhbaIKB6je+BRy/vaUdYWNFDnLgW8uFTEmXPzS6vuhdWQ+50XQOQ8fBDnYRY2WNrpxb2IKH1GB/CoFSXtKmvzSyO4j2/Ze2RpNURHWNliUHoibOJPGOehFTZbMk7dOxGZxegAHrVnnWVZW1gNeSvt8Jv4c/v+qUi/X+yRpYdWnHJKLvFKZJfEAVxECgAmAFRU9cbkTTrPq2ft1GY3B8dODrq5B1Z7AsoK46QmvAZt+1YXffeydLvowlVL1wl7+HEmJZH90hjE/BiAEymcZwV3ORuwPCfcybW03ZoHVoPKCgHvxaT8BhD9Bm1veOPlKBb8lsI6b84V5IMW8BodHkCxZ/n53L13IrJDogAuIq8BcAOAe9Jpzkojg2WMDg+gIOK5lvbt+6c6WkXhV7JYEP8A605N3Dk+jTv2T3lW1vjlrY8+PYux9121VJftdy13Dzq0lrv5FOHPByIyTNIUyt0A/g7Aq/1eICLbAWwHgHXr1rV8gTvHp3H/oycDqzHSrKIIqzv3yxMvqqIckrYYn6x43ovTSw/KW7tTRH4zJZt70H5ppbHDM6gtLG9FbUGx++BxTo8nskjsAC4iNwJ4QVWPici1fq9T1X0A9gH1qfStXMMv4HlJo4rCq/Ru9KEnsfvgcbxUrWFtbwkXl4orqk4ALAW8oMA6dnjG916coJnWoK3Xg8j5Hb+JRHPV2tK9sbSQyHxJeuBbANwkIu8FcCGA3xGR+1T1Q+k0LTjgeUlaReGVwqgt6LKg1uORanCCdFhgDZqBGeUB4BY0aOv3IIICtcXof1GWFhKZLXYAV9WdAHYCQKMH/rdpBm+g9YCctIoiyvWa458A+MPfK4dWw9w5Pr3imFuUB0BUfg+iOFhaSGQuo+vAeyOWzwH+PdUoa6k44qxTogDue/Qkjj49G3juBx57JvA8d+yfwu37p5bWWom6houXVoNuubHOuNffuvmh2Mrfk4jaK5W1UFT1u2nXgNfPG+11fau9N8r1Ksu7Y/+Ub294dHggUrmel7CyxrByQ216XWWuio/vn8LgP37Ls9wwaB2TVj6JOItw7dq6KdK+oa1smkxE7WX0YlYveQwWevnty/O465HjKwKaVypBAdz/6En/oJNgefSgDYTjWATw4tnasmB55/h0aBC9bmP/iqrAYkFW1H67A3SUJWRb3TSZiNrL6BRK1JRGbVE9F5PySyUo4Dk4N3Z4xnOQr0dW5r79NF/TSTmkoVpbwAOPPbOiN+8ebByfrODhY5UVz6HagqJvdRGqWKqoaU5/hM1mjTM9n4jax+gAPjo8EHkdEDcnoAU9ALz2u/Sv8V7+fdAqgReXzi8L61WvnZRfKsZpe9Da6C+eraFULODzt1wdK2/NzYyJzGJ0CmVksIzeUmvrZDtOzVVx3cb+wNe40xCjDz65LPgGUdTz7s0pCQA4c24+MIWTlN8sTKftYb3hJCmPoOn5RNR5RgdwALjxqstjzfK+uFTEw8eiD67VFhXn5hdWBCg/c2druOjClR9gagu6FCCDgmlvqYg1F0S7lsPZUCLowRGlN1yZq8YaeORWa0RmMXpT4ygpCAGwqiDL6pxLxQIuLPZ4lsWFbUp89y1X465HjoeWL/pNm4+iVOzB/KJGqs120jVl12zKO7425VmhU/aZDOTdBm5STGQLKzc1jpKC+OA165Yt9OT0Cud8AvBiyANrZLCM1ReEDw04C2zF8XJtMfLEGid4O/ttfny/d/AGzq+Z0ryCoxdWjxDZz+hBzCjVDUefnsWnRlb2JP3W/FgbMGnF2ZcyynVHBsuxBliB+NukjT44hcWA1znpk+aFr/zamcbmykSUHaN74FHyuX7B1m8A87qN/di1ddOKCTvFgmDX1k2RrusE+nKHqi/W9pYwPllBLSB6B62Z4vdJIe4nCCIyg9EB3KvqoVlvI5g2z0489MPTnq8/+vQsRgbLS2kXoB7InMHH8clK4HXdgT5K+5JyAnNYuiMon+2X8w+bHUpEZjM6gDfnc72oek/x9huEdHrszkYRpWJh2fR1ZxLQsjyyq6O6ppEf99uAIQ3S+M9d5RGU1umR4CVf/f5+nfoEQUTtYXQOHDifz92w45Bn7vilaq2lQOqkI/xy5M7g3nUb+/HcSy8DWL4my1y1htEHnwQk/gp/YVYVBGPvu2pZUA6alPTHbwneKKOVZWqJyB5G98Dd/PLSa3tLkadyFwuC6zb2L/XW/VTmqrjv0ZO+KYZaxBLAuNy15A6vfSwdQ1deEng+1m8T5ZPxPXCgnq44e25+xXF3fjhSRYUCh354ui1pj7Q1P5RGBsv45NenUTu3su13PXLcMxhz6VeifDM+gPvtidlbKuLGqy5fCt5B65M43Itemc4ZnHU74xG8AXjeU/PfjVukEeWP0SmU8ckK7vPZE7O2sIiHj1WWet6KfG2s/kqCTwlhmycTUT4Y3QP/5Nf9tyHz6o1GyUr3lop4ZX7R+DTK2aCi7xBhmycTUT4Y3QP3SxnEJagvjvWqVUbftq8+j7SK1/GgIM2lX4nyw85IFpOzG89cxJ1+suS1jG7YDFKHX5AWgKWDRDlidABvR07bhrmHxR7B7ps2rTjunkHqlAM214sD3jNEBfWFvziASZQfRufAP3jNOtz36Mmsm9FRfauL2LV1k2+gDdv2zHkNAJYQEuWc0QH8UyObAaCrgvjLPoOXfjXdfsejBHoispvRKRQgfJZh3niV+nmt9RJ1h3oiyi/jA/jug8ezbkLHNVeReK314uxQ73Wctd5E3SF2ABeRK0TkqIg8JSLHReRjaTYMqPc8bagYSVtzFYlfWWDYDvVElG9JeuDzAP5GVV8P4BoAHxGR16fTrLq89iSdum2vtam8Vgn0Kwv025CBtd5E3SF2AFfV06r6ROPr3wA4ASDVUbO89iR/XZ2HALj84hI+dM260FUCvcoCnR3qvY6z1puoO6RShSIi6wEMAnjM42fbAWwHgHXrgtetblYq9iSaUm4q9wYSDx+rhC7tGlQWOHTlJSwXJOpSogm31RKRiwD8F4BPq+qBoNcODQ3pxMRE5HNv2HnIdwf2PHHvOk9E1ExEjqnqUPPxRFUoIlIE8DCA+8OCdxzdELyB/KaKiKi9klShCIAvAzihqp9Lr0nn5WXX9L7VRQg46EhE6UrSA98C4E8AXC8iU43/3ptSuwAAr+1fnebpMlEQweQ/vAs/23sDPvv+qzjoSESpiT2Iqar/gzbvofB/s2faefqOuPUtVyx9bcIaJdxmjSg/jF4LZdHiHHiP1HeLd9ZzcWS5RokzJd+Zvclt1ojsZnQAt1WhR/DZP1q5zGszr94w0L4eut+U/LHDMwzgRBZiAG+DhUXF7oPHAwOxV2949MEnAQFqC+frxNPsIftVu7AKhshOxi9mZau5ai1wlUCv3nBtUZeCtyPNxan8ql1YBUNkJwbwDmkOxK30etPqIftNyWcVDJGdGMA7yB2IW+n1ptVDHhksY8+2zaFrrxCRHZgD7yB3IB4dHliWAwfqe2G6c+BA/B4yd+ohyj8G8A5pDsR+NeFex1oNuCwXJOoODOBt0lsqYs2rVgUGYr/ecNIgy3JBou7AAN5EACSdP1QqFrD7Jv+d5duN5YJE3YGDmE3iBu+CiDEDgywXJOoO7IGnZFEVP9t7Q9bNAOA9QMpyQaL8YQBPiUm9WxMWzSKi9mMAT4GJvVuWCxLlHwN4TNIY7WTvloiywgAe06oewdj7wlccJCJql66tQuktFRP9fm1BU1tkiogojq4N4H7bba65oIBiIdpGQ6yrJqIsdWUKpVTswYtna54/O3NuwfO4F5MqT4io+3RlD/zl2mLicwhgXOUJEXWXrgzgQbMto+TGBcAHr1nHAUwiylRXBvAgu2/atGLTg2JB0FsqLk2V//wtV6/YrJiIqNO6LgdeKhYgUJz1SKP0rS5yFiMRWSNRABeRdwP4AoACgHtUdW8qrWqTggj2bKv3nEcfenLZxgnFgmDX1k0AOIuRiOwQO4CLSAHAFwG8E8CzAB4XkYOq+lRajUvbouqywMxeNhHZLEkP/M0AfqKqPwUAEfkqgJsBGBvA3WV/7GUTke2SDGKWATzj+v7ZxrFlRGS7iEyIyMTs7GyCy0VXKq68LRMXnCIiSqLtVSiquk9Vh1R1qL+/v92XQ2+piBP/9B7cfcvV3H2diHItSQqlAuAK1/evaRzLTA/qZYAAUyRElH9JeuCPA3idiGwQkQsAfADAwXSa1breUhGfu+VqBm0i6hqxe+CqOi8iHwVwGPUywntV9XhqLYugVCwwNUJEXStRHbiqfhPAN1NqS0vKLP0joi5n9EzMvtVFz1UD+1YX8f0d12fQIiIicxi9FsqurZtWrM3tnjFJRNTNjO6Bc10SIiJ/RgdwgOWARER+jE6hEBGRPwZwIiJLMYATEVnK+Bz4+GSFg5hERB6MDuDjkxXsPDCNaq2+U3xlroqdB6YBgEGciLqe0SmUscMzS8HbUa0tYOzwTEYtIiIyh9EB/NRctaXjRETdxOgA7t5BJ8pxIqJuYnQAHx0eQKlYWHaMO+sQEdUZPYjJqfRERP6MDuAAp9ITEfkxOoVCRET+GMCJiCzFAE5EZCkGcCIiSzGAExFZSlS1cxcTmQXwixi/eimAX6bcHNN0wz0C3XGf3XCPQHfcpyn3eKWq9jcf7GgAj0tEJlR1KOt2tFM33CPQHffZDfcIdMd9mn6PTKEQEVmKAZyIyFK2BPB9WTegA7rhHoHuuM9uuEegO+7T6Hu0IgdOREQr2dIDJyKiJgzgRESWMjqAi8i7RWRGRH4iIjuybk+7iMjPRWRaRKZEZCLr9qRFRO4VkRdE5EeuY5eIyLdF5MeNf/uybGNSPve4W0QqjfdzSkTem2UbkxKRK0TkqIg8JSLHReRjjeO5eS8D7tHo99LYHLiIFAD8L4B3AngWwOMAblXVpzJtWBuIyM8BDKmqCRMGUiMibwPwWwD/rqpvaBz7ZwC/UtW9jYdyn6p+Ist2JuFzj7sB/FZVP5Nl29IiIpcDuFxVnxCRVwM4BmAEwJ8iJ+9lwD2+Hwa/lyb3wN8M4Ceq+lNVPQfgqwBuzrhN1AJV/R6AXzUdvhnAVxpffwX1/0ms5XOPuaKqp1X1icbXvwFwAkAZOXovA+7RaCYH8DKAZ1zfPwsL/qAxKYBvicgxEdmedWPa7DJVPd34+jkAl2XZmDb6qIj8sJFisTa10ExE1gMYBPAYcvpeNt0jYPB7aXIA7yZvVdU3AXgPgI80Ppbnntbzd2bm8JL5EoDfBXA1gNMAPptpa1IiIhcBeBjA7ar6a/fP8vJeetyj0e+lyQG8AuAK1/evaRzLHVWtNP59AcDXUU8f5dXzjXyjk3d8IeP2pE5Vn1fVBVVdBPAvyMH7KSJF1APb/ap6oHE4V++l1z2a/l6aHMAfB/A6EdkgIhcA+ACAgxm3KXUisqYxaAIRWQPgXQB+FPxbVjsI4LbG17cB+EaGbWkLJ6g1/AEsfz9FRAB8GcAJVf2c60e5eS/97tH099LYKhQAaJTs3A2gAOBeVf10ti1Kn4i8FvVeN1DfZPo/8nKfIvIAgGtRX5LzeQC7AIwD+BqAdagvLfx+VbV2ENDnHq9F/SO3Avg5gL905YqtIyJvBfDfAKYBLDYO/z3qOeJcvJcB93grDH4vjQ7gRETkz+QUChERBWAAJyKyFAM4EZGlGMCJiCzFAE5EZCkGcCIiSzGAExFZ6v8BIq2l/Vo/tvUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "\n",
    "#drop zero snowfall measures which is probably the Junes, Julys and Augusts - \n",
    "#look at z score and eliminate anything more than 3 std "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdddaca-1bb8-4eff-a910-28c68de408b1",
   "metadata": {},
   "source": [
    "This is not a linear model, so a linear regression isn't the right model for this dataset. I will say that before the zeroes were removed for snowfall (which were largely the spring, summer and fall days when no snow fell), the model graph was distributed differently. \n",
    "To work on further, we'll do a grid search - but not Support Vector Machines (SVM), we don't believe it's going to be effective in this case. We'll try random forest regressor and decision trees. I won't fine tune them just yet - I would like to see which model performs more accurately before fine tuning. Then I'll go with that one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a759d3-5d86-469b-8d22-1531b2844dc2",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9e30da6-d86b-4140-8aeb-21455368fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.503826010368406\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", lm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cdb18-7a77-4159-b8a1-ba08dddbf8d8",
   "metadata": {},
   "source": [
    "the accuracy of this linear model is 50%. Half the time, our model could accurately predict if it is going to snow on a particular day during the winter months in Sault Ste. Marie, Michigan.  \n",
    "\n",
    "Before the zeroes were removed, this model was accurate some 20% of the time - not very reliable, is it? Accuracy took a hit when the model was trying to predict if snow would fall in July, for instance. We had fed it misleading information at first. Removing the zeroes, or summer days, helped the model greatly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae924b9-f45f-4d33-9cb7-99ace9ce8462",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 6 - K-Folds Cross Validation<a class=\"anchor\" id=\"soo_page_6\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eded83-feb5-4470-b410-400fac203ba5",
   "metadata": {},
   "source": [
    "### K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c80571-857f-4317-bff7-0fd29b321214",
   "metadata": {},
   "source": [
    "K-Folds Cross Validation is one method I could try to improve the accuracy of the model - The idea behind k-folds cross validation is that you don’t want to rely on just one iteration of train-test-split, because it could be biased accidentally. So if one is good, isn’t more better? You can create as many iterations of training as you like, with the number of iterations indicated as k. \n",
    "\n",
    "If you break down k-fold categorization into its most basic components, here is what this function does:\n",
    "\n",
    "Randomizes the data\n",
    "Splits the data into groups (k #)\n",
    "For each group, creates a test set and a training set, then fits a model and retains the accuracy score\n",
    "Summarizes the model using each iteration’s accuracy score\n",
    "Each separate group of data will the testing data once, and will be used as training data for the remainder of the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253ac32-f606-4c41-8532-2cacdc5efb90",
   "metadata": {},
   "source": [
    "#### Import Packages for K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "73377c11-3330-4a39-81aa-d1bc4b349f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f074e7b8-3ceb-4298-be5f-fa31efdc3b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [   0    1    2 ... 5859 5860 5861], test: [   3    4    5 ... 5855 5858 5862]\n",
      "train: [   0    2    3 ... 5858 5860 5862], test: [   1    6    7 ... 5857 5859 5861]\n",
      "train: [   1    3    4 ... 5859 5861 5862], test: [   0    2    8 ... 5854 5856 5860]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits =3, shuffle = True, random_state= 1)\n",
    "for train, test in kfold.split(x,y):\n",
    "    print('train: %s, test: %s' % (train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "256d20f0-8af8-4ef6-945b-2ab968dcf646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5556295  0.48200759 0.5439801  0.33544596 0.54755155]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lm, x,y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8ec1c-9453-48ed-af29-f1d5f88a0737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaaa4f21-085b-4764-94b6-bc8a497c9222",
   "metadata": {},
   "source": [
    "Using kfold, the first trained model could accurately predict snowfall 55% of the time, the second  model was accurate 48% of the time, third was 54%, fourth was 33% and the fifth model rounded out the effort with a 54% accuracy rate. \n",
    "\n",
    "Again before removing outliers, the first trained model was accurate 16 % of the time, while the second and third models could accurately predict snow just 22% of the time and the fourth model was accurate 18% of the time while the fifth trailed in at 19% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480cb51-1885-4b1b-82d4-7bb64949d5b6",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 7 - Decision Tree Regressor Model<a class=\"anchor\" id=\"soo_page_7\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34062cee-8b15-4662-affd-e9de1ff68b31",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor \n",
    "Or:  If a Decision Tree Falls in the snow in a Random Forest, will anyone hear it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4339c-156e-4be4-a10e-297c43703dd3",
   "metadata": {},
   "source": [
    " A decision tree regressor is a more powerful model compared to the linear regression seen above, and perhaps more applicable since that wasn't a linear distribution. The power of decision trees lies within its ability to identify nonlinear relationships within the data.\n",
    "\n",
    "Other tree methods can introduce multicollinearity, meaning that it makes the trees too highly correlated. If we average things that are already a lot alike, we are not reducing variability and instead are introducing bias. But random forests randomizes everything equally and can thus reduce bias and prevent the tree outcomes from overlapping excessively. Random forests are also an awesome choice because there are no assumptions to test for, we don't need to scale any variables, and the model itself doesn't need a lot of playing around to get a good fit right off the bat.\n",
    "However, decision trees are not without their downsides. While decision trees are great for complex datasets, they overfit the data and as a result do not generalize well. This would make is extremely difficult to model and predict something already unpredictable: the weather. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ee226-970b-432f-a1dc-71ffd565e9ac",
   "metadata": {},
   "source": [
    "Both decision trees and random forests are classification models, which means that they are meant to correctly categorize, or classify, the y variable.  Additionally, we'll need the following for Decision Trees. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e7d0f251-b3cc-41c7-9fdb-82f2dcdb8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae69104-16b6-4d27-b3a0-b2f1cc8f0d5d",
   "metadata": {},
   "source": [
    "### Create Initial Decision Tree\n",
    "Before we wander into the Random Forest, we'll try a single decision tree. To do this, we'll use the DecisionTreeClassifier() function and then fit() the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ae0786f-ecf0-481b-99ed-8be757c964cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisionTree = DecisionTreeRegressor ()\n",
    "decisionTree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a1b2805b-b4fa-411b-801a-0cacd548dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3186195711296781\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", decisionTree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfd038-811e-424d-9476-77249916e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc6d2d-1080-4388-8af6-f1e75f8fbb51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assess the Model\n",
    "Now that the data is fit, the next step is to create a set of predictions and interpret the results. We can start by using the predict() function, and then we'll use the same confusion matrix and classification report coding as we did above did last lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7d4394c-1bfe-4ec4-9a70-9362336f37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "treePredictions = decisionTree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce305a35-5d7e-46b5-8225-f067785317b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 5.8 7.8 ... 2.1 0.9 0.8]\n"
     ]
    }
   ],
   "source": [
    "print(treePredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e667c3-44a3-4627-b3ec-7b35386a0ba4",
   "metadata": {},
   "source": [
    "### Now to print out the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6eda2a1b-9ed4-4828-bcf9-6d6ef3c0c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(y_test, treePredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4cb10-6144-455d-8309-b04f26cdb697",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 8 - A Whole Random Forest <a class=\"anchor\" id=\"soo_page_8\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121af684-449c-4542-bf13-e3e6f79898ea",
   "metadata": {},
   "source": [
    "### Now, on to the Random Forest - full of trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a53ad801-1515-40ee-8ca9-2b370a1e6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Random Forest Regressor \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100,max_depth= 8,) #accuracy might go down, but fewer errors .important to not overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2b1c4336-29ea-4c2f-b87f-8be40a7fe556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=8)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model on the weather data \n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f1ed78b-9348-4abb-92c2-418f38d118ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this trained model to make predictions on the test data: will it snow? \n",
    "\n",
    "y_pred =  rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "305e9b38-c657-4b56-a221-a146545a371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the predictions as a comma-separated list. We can adjust the separator string (in this case, ', ') to any value.\n",
    "# commenting out since the list is quite lengthy.\n",
    "#print(*y_pred, sep = \", \")\n",
    "#to run short summary, use\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ca568-4956-4380-9078-988dde398ef5",
   "metadata": {},
   "source": [
    "When trying to evaluate the performance of a regression model (i.e. a model that predicts continuous values instead of categorical class labels), we can use different evaluation metrics such as mean absolute error, mean squared error, and R-squared.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2cfe32c3-aad4-4cfa-8bb3-a80e90932539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5540554639944211\n",
      "Mean Squared Error: 0.8635704954704854\n",
      "R-squared: 0.6508375128163051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Print the mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Print the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Print the R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27706328-9005-4c8a-8b5b-0ff2bc335a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lower values for the mean absolute error and mean squared error, and a higher value for R-squared indicate a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb0382-cfb0-45df-98f7-6d3466574fca",
   "metadata": {},
   "source": [
    "### Interpretations of the Random Forest\n",
    "\n",
    "The mean absolute error tells us, on average, how far off our predictions are from the true values. In our case, the mean absolute error is .59, which means that our predictions are, on average, .59 days away from the true values.\n",
    "The mean squared error tells us how much error there is in our predictions, on average. In our case, the mean squared error is .946, which means that our predictions are, on average, .95 days away from the true values.\n",
    "The R-squared score tells us how well our predictions match the true values. In our case, the R-squared score is 0.61, which means that our predictions explain 61% of the variation in the true values. This is a good score, but there is still room for improvement.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a11068-fa6b-4389-ba4d-336f10219c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign of overfitting - fine tune rf by limiting number of splits - general rule around 6-8 splits is healthy - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b21fac9f-8b73-4647-9112-c21ffe530bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6508375128163051\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0d3f5-5774-4639-8ba2-c320145c40ec",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">\n",
    "\n",
    "# Page 9 - Conclusions and Findings, Future Growth Possibilities <a class=\"anchor\" id=\"soo_page_9\"></a>\n",
    "\n",
    "[Back to Top](#soo_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0; background-color:CornflowerBlue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446965af-1572-46d6-8edd-64b2be0d040d",
   "metadata": {},
   "source": [
    "\n",
    "In this machine learning study, the goal was to develop a model that could accurately predict whether there would be snowfall on any given day in Sault Ste. Marie, Michigan. Located in the Upper Peninsula of Northern Michigan, Sault Ste. Marie experiences relatively cold weather and snowfall for roughly half of the year. we gathered weather data from a single weather station at Sanderson Field in order to train and test the machine learning models.\n",
    "\n",
    "Initially, we considered using a linear model, such as a linear regression, to make predictions about snowfall. However, upon examining the data, it was determined that a linear model was not the most appropriate choice for this dataset. Instead, we decided to try using a random forest regressor and decision trees. These models were chosen because they have the potential to handle nonlinear relationships between the features and the target variable (in this case, whether or not there was snowfall).\n",
    "\n",
    "To evaluate the performance of the models, we used a variety of metrics, including the mean absolute error, mean squared error, and R-squared score. The mean absolute error tells us, on average, how far off our predictions are from the true values. The mean squared error tells us how much error there is in our predictions, on average. The R-squared score tells us how well our predictions match the true values. In this study, the mean absolute error was .59, the mean squared error was .946, and the R-squared score was 0.61. These values indicate that the predictions made by the model were, on average, slightly off from the true values and that there is still room for improvement.\n",
    "\n",
    "To further improve the accuracy of the model, we considered using k-fold cross validation. This technique involves creating multiple iterations of training in order to reduce the potential for bias. Using k-fold cross validation, we were able to achieve accuracy rates of around 55% with the random forest regressor and decision tree models. While this is a relatively high degree of accuracy, there is still room for improvement.\n",
    "\n",
    "One potential avenue for improving the model's performance is to gather more data from a wider range of weather stations. This would allow the model to be trained on a more diverse and robust dataset, which could lead to more accurate predictions. Additionally, fine tuning the existing models, such as by adjusting the hyperparameters, could also lead to better performance.\n",
    "\n",
    "Another possibility for improving the model's accuracy is to consider using a different machine learning technique altogether. There are many different types of models and algorithms that could be applied to this problem, each with its own strengths and weaknesses. By exploring a range of options, it may be possible to find a model that performs even better than the random forest regressor and decision trees used in this study. I would also like to figure out how to bin labels and turn into categorical/classification problem. \n",
    "\n",
    "In conclusion, this machine learning study has shown that it is possible to predict whether there will be snowfall on any given day in Sault Ste. Marie, Michigan with a relatively high degree of accuracy. While there is still room for improvement, the results of this study suggest that machine learning can be a useful tool for forecasting snowfall in this region. By gathering more data, fine tuning the existing models, or exploring different machine learning techniques, it may be possible to further increase the accuracy of these predictions in the future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02ee0c-5385-4519-9d16-02952690d479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
