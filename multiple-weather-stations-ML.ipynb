{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10735e93-d3e9-4cf0-a5d5-a77a13686e43",
   "metadata": {},
   "source": [
    "# Northern Michigan Snowfall Prediction using Machine Learning Models \n",
    "### Or:  If a Decision Tree Falls in the Snow in a Random Forest, Will Anyone Hear It?\n",
    "\n",
    "\n",
    "\n",
    "#### Supervised Machine Learning: Multiple Weather Stations Machine Learning Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb37be-ddaa-41bd-b3a1-de4cf813b276",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"text-align: center \">\n",
    "  <img  src=\"Media/snow-flowers.png\" width=\"800\" height = \"400\" alt=\"snowbank\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582182f-66b9-4a03-a9c6-012a8a731446",
   "metadata": {},
   "source": [
    "How accurately can I create a model that can predict whether there will be snowfall on any given day, or just Christmas Day in Sault Ste. Marie, Michigan? \n",
    "Sault Ste. Marie is located at the top of the Upper Peninsula, in Northern Michigan. It comes from the French, so it's pronounced \"Soo Saint Marie, \" or \"the Soo,\" for short. The city's name comes from Saults de Sainte-Marie, archaic French for \"Saint Mary's Falls\", a reference to the rapids of Saint Marys River. \n",
    "\n",
    "Pristine lakes and waterfalls, my favorite people in the world and abundant trees make this one of my favorite places on Earth. Given it's north of the 45th parallel, it's not the warmest year-round. There can be snow on the ground for some six months of the year, lasting from late October with the last bits finally disappearing around the beginning of May. So it's not a stretch to predict if there will be snow on the ground in December - but will there be a new blanket of fresh white snow to wake up to on Christmas Day?  That may take a bit more finesse to figure out. \n",
    "\n",
    "We gathered datasets from weather stations in and near Sault Ste. Marie and the surrounding Chippewa County in order to have a more robust dataset. Links to the data from the National Centers for Environmental Information/ NOAA can be found [here](https://www.ncei.noaa.gov/access/past-weather/49783).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95b26817-6f97-4410-96eb-83bfe0105bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f747c430-f10c-4368-9dcc-071a39dd2153",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create list of CSV file names for each weather station located in Chippewa County, Michigan. Weather stations just across the river in Ontario, Canada are not included in this dataset.\n",
    "wxstations = ['DATA\\Dunbar.csv', 'DATA\\Kincheloe AFB.csv', 'DATA\\Kinross.csv', 'DATA\\Rudyard.csv','DATA\\SSM 7-1SSW.csv','DATA\\SSM.csv','DATA\\SSM2-1E.csv','DATA\\SSM7-8SE.csv', 'DATA\\Sault-Weather.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5fd9ba7-d4bb-4eb1-84bd-5d372bbaeba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>SnowDepth</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/1942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/1942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/1942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/1942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  AvgTemp  MaxTemp  MinTemp  Precip  Snowfall  SnowDepth  \\\n",
       "0  1/1/1942      NaN     27.0      6.0    0.06       1.0        5.0   \n",
       "1  1/2/1942      NaN     20.0      3.0    0.66       8.0       13.0   \n",
       "2  1/3/1942      NaN      9.0     -6.0    0.01       0.5        NaN   \n",
       "3  1/4/1942      NaN     17.0     -9.0    0.00       0.1        NaN   \n",
       "4  1/5/1942      NaN     10.0    -16.0    0.00       0.0        NaN   \n",
       "\n",
       "   Unnamed: 7  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.concat((pd.read_csv(i) for i in wxstations)).reset_index(drop = True) # Import the weather station files \n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ec1b287-e46a-4d9a-9737-dfa3147d06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70731, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1825b172-43ff-494a-91ba-42c5fabbe39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>SnowDepth</th>\n",
       "      <th>Snowfall</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6130.000000</td>\n",
       "      <td>67601.000000</td>\n",
       "      <td>67229.000000</td>\n",
       "      <td>70557.000000</td>\n",
       "      <td>17101.000000</td>\n",
       "      <td>66675.000000</td>\n",
       "      <td>51700.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.643393</td>\n",
       "      <td>50.552743</td>\n",
       "      <td>31.456975</td>\n",
       "      <td>0.093173</td>\n",
       "      <td>0.279025</td>\n",
       "      <td>4.970815</td>\n",
       "      <td>0.311752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.441502</td>\n",
       "      <td>21.187006</td>\n",
       "      <td>19.636747</td>\n",
       "      <td>0.225175</td>\n",
       "      <td>0.933023</td>\n",
       "      <td>8.294622</td>\n",
       "      <td>1.013510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AvgTemp       MaxTemp       MinTemp        Precip      SnowFall  \\\n",
       "count  6130.000000  67601.000000  67229.000000  70557.000000  17101.000000   \n",
       "mean     43.643393     50.552743     31.456975      0.093173      0.279025   \n",
       "std      19.441502     21.187006     19.636747      0.225175      0.933023   \n",
       "min     -15.000000    -12.000000    -39.000000      0.000000      0.000000   \n",
       "25%      29.000000     33.000000     19.000000      0.000000      0.000000   \n",
       "50%      45.000000     51.000000     33.000000      0.000000      0.000000   \n",
       "75%      61.000000     69.000000     47.000000      0.080000      0.000000   \n",
       "max      81.000000     98.000000     72.000000      5.920000     27.000000   \n",
       "\n",
       "          SnowDepth      Snowfall  Unnamed: 7  \n",
       "count  66675.000000  51700.000000         0.0  \n",
       "mean       4.970815      0.311752         NaN  \n",
       "std        8.294622      1.013510         NaN  \n",
       "min        0.000000      0.000000         NaN  \n",
       "25%        0.000000      0.000000         NaN  \n",
       "50%        0.000000      0.000000         NaN  \n",
       "75%        8.000000      0.000000         NaN  \n",
       "max       50.000000     26.600000         NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are different numbers of rows for each of the columns, due to differences in when the weather stations were installed, if they were offline for any amount of time, and other NAs.\n",
    "\n",
    "stations.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0270a2bc-a225-488f-a1b6-91e506ba0e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70731"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26eb7f97-0f50-422d-a6ef-7a27d33355d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations = stations.iloc[[2:70731], [2:7]]  #uses integer locators so you don't have to type out label column names\n",
    "stations = stations.loc[0:70731,['MaxTemp', 'MinTemp', 'Precip', 'Snowfall', 'SnowDepth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5361210-1b0e-4075-9462-7c2862b378b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9163e5b0-0223-49c7-bc5a-d8ff06cfdc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxTemp      3130\n",
      "MinTemp      3502\n",
      "Precip        174\n",
      "Snowfall     1930\n",
      "SnowDepth    4056\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(stations.isna().sum()) \n",
    "\n",
    "#number of NAs in each column - note these NAs may be in different rows. \n",
    "#For instance, an NA in a particular row in one column may not have more NAs across the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5c14761-afd7-44eb-8adc-12a46cf8ab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70730, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f0c02-db63-47a7-bc8f-a92086a0e3d5",
   "metadata": {},
   "source": [
    "This dataset has 70,730 rows with five columns that we're interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa32da93-303f-4370-8e3e-fc360ff9fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12792\n"
     ]
    }
   ],
   "source": [
    "print(stations.isna().sum().sum()) #total number of blank NA cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fc2105b-3957-49ef-b518-5430c4eb3a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424386"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "70731*6 #total number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2893653-397a-4021-b5fd-8d6e7ba8d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030142370389221133"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12792/424386"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65077ee-247a-4f32-8863-fb4fc690f60f",
   "metadata": {},
   "source": [
    "Just 3 % of the dataset are null values - which is a safe number to drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa3a6371-9099-4166-be02-5a0764278452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, we'll keep all the zero values when no snowfall was recorded - as in the spring, summer and autumn months. \n",
    "#Keeping this code here for possible use later. \n",
    "#snow = snow[snow['Snowfall'] != 0   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71d919e9-d022-4d96-ae21-5a66bdcbf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers.  Removing just two std dev - Absolute value of the standard dev from z score, on each value in each column \n",
    "\n",
    "#stations = stations[(np.abs(stats.zscore(stations)) < 2).all(axis=1)]\n",
    "#stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485f4eb-6986-45c8-8e25-62646f1fc0d8",
   "metadata": {},
   "source": [
    "### Dropping null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e902137-13c2-4a16-9523-4f8179968c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = stations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12eb41d6-b9da-4295-b4f5-6e5233365734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64368, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see how many rows are lost after dropping NAs - \n",
    "stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861a919-dbad-440e-bca6-74e3c0d882a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46382a83-371c-41b0-9a57-a828d33c6369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aca5dc6-384d-47cd-b3ad-8db35f66ed27",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    "One of the key things that separates machine learning from statistics is that machine learning utilizes the concept of \"train test split.\" In statistics, you typically run your analysis on all the data you have available. In machine learning, you split your data in half, and reserve the first chunk for training the model, and the second half for testing the model. How big should a \"chunk\" be? Typically you want more data to be used for training than for testing. 80/20, 70/30, and 60/40 splits are all acceptable.\n",
    "\n",
    "\n",
    "You will utilize the train_test_split() function from sklearn to split your data. You will end up with four data sets at the end:\n",
    "\n",
    "\n",
    "* x_train\n",
    "* x_test\n",
    "* y_train\n",
    "* y_test\n",
    "\n",
    "There will be one training dataset and one testing dataset each for x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd13bb69-7065-4014-852b-8af53632aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y consists of the target variable, or what I'm trying to predict. X is the group of variables that will be used to learn how to predict the y variable - or snowfall.\n",
    "\n",
    "x = stations[['MaxTemp', 'MinTemp', 'Precip', 'SnowDepth']]\n",
    "y = stations['Snowfall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da490812-7d7e-4f31-be8e-f929a1048578",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "#### One of the key things that separates machine learning from statistics is that machine learning utilizes the concept of \"train test split.\" In statistics, you typically run your analysis on all the data you have available. In machine learning, you split your data in half, and reserve the first chunk for training the model, and the second half for testing the model. How big should a \"chunk\" be? Typically you want more data to be used for training than for testing. 80/20, 70/30, and 60/40 splits are all acceptable.\n",
    "\n",
    "You will utilize the train_test_split() function from sklearn to split your data. You will end up with four data sets at the end:\n",
    "\n",
    "x_train\n",
    "x_test\n",
    "y_train\n",
    "y_test\n",
    "\n",
    "There will be one training dataset and one testing dataset each for x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc9e3ef9-9211-4062-b6e9-dbd6829dfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = .4)\n",
    "\n",
    "#reduced to 60/40 split to give more opportunity to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e8f7be3-a76a-4e26-a86d-e954026ae886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38620, 4) (38620,)\n",
      "(25748, 4) (25748,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbb08b3-e4f8-41f4-b917-276b922bf2f5",
   "metadata": {},
   "source": [
    "With a 60/40 split for the train/test splits, we see in the training datasets, there are 38620 rows and 4 columns, and in the testing dataset, there are 25748 rows and 4 columns. So you can see how the training and testing data is broken up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741be779-f467-4c46-86bd-59b91de0ffda",
   "metadata": {},
   "source": [
    "## Checking to see if a linear model will fit the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ee127c5-8444-4c3b-bc06-483ff50d875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression() \n",
    "lm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3214fb34-630b-4bfc-883f-21830565ae32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36735931,  0.63030529, -0.03828584, ...,  0.70602676,\n",
       "        1.10193416,  0.48794255])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model created, examine predictions\n",
    "\n",
    "predictions = lm.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e83c736-692f-445c-a678-6370dded15f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2113457bc10>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgG0lEQVR4nO3df5Ac5Xkn8O+zo5GYlR2NZNYOGiSEKUrUER0s7IEuyqWAXCwCNt4DnwVlLs6PKiqVc1WEHeVWCRVEijqU23LsXJK6K852xT5jssRS9jCSS+ZOSqVCSgortGItI4UfxhKLYjZBKwd2bEazz/0x06Oe3n57umd6et6e/n6qVNrt+fVuT/fTbz/99PuKqoKIiOw10OsGEBFRMAZqIiLLMVATEVmOgZqIyHIM1EREllvWjTe99NJLdcOGDd14ayKivnT06NF/UtUhv8e6Eqg3bNiAqampbrw1EVFfEpEfmB5j6oOIyHIM1ERElmOgJiKyHAM1EZHlGKiJiCzXlaqPdkwem8X4gVN4c76MtcUCdmzdiNHhUq+bRUTUc1YE6sljs9i5dwblShUAMDtfxs69MwDAYE1EmRc69SEiORE5JiLPxN2I8QOnGkHaUa5UMX7gVNwfRUSUOlFy1L8F4KVuNOLN+XKk5UREWRIqUIvI5QDuBPClbjRibbEQaTkRUZaE7VF/EcDvAFg0PUFEHhCRKRGZmpubi9SIHVs3opDPNS0r5HPYsXVjpPchIupHLQO1iHwUwFuqejToear6uKqOqOrI0JDvuCJGo8MlPHb3JpSKBQiAUrGAx+7exAuJREQIV/WxBcBdInIHgEsA/JSIfF1V74+zIaPDJQZmIiIfLXvUqrpTVS9X1Q0A7gVwMO4gTUREZrwzkYjIcpFueFHVvwbw111pCRER+WKPmojIcgzURESWY6AmIrIcAzURkeUYqImILMdATURkOSvGowY4cQARkYkVgZoTBxARmVmR+uDEAUREZlYEak4cQERkZkWg5sQBRERmVgRqThxARGRmxcVE54Ihqz6IiJayIlADnDiAiMjEitQHERGZMVATEVmOgZqIyHIM1ERElmOgJiKyHAM1EZHlGKiJiCzHQE1EZDkGaiIiyzFQExFZjoGaiMhyDNRERJZjoCYishwDNRGR5RioiYgsx0BNRGQ5BmoiIssxUBMRWY6BmojIctbMmTh5bJaT2xIR+bAiUE8em8XOvTMoV6oAgNn5MnbunQEABmsiyryWqQ8RuURE/l5EjovICRF5JO5GjB841QjSjnKlivEDp+L+KCKi1AnTo/4JgNtU9R0RyQP4WxH5tqoejqsRs/PlSMuJiLKkZY9aa96p/5qv/9M4G5ETibSciChLQlV9iEhORKYBvAXgWVU94vOcB0RkSkSm5ubmIjWiqv5x37SciChLQgVqVa2q6vUALgdwk4j8jM9zHlfVEVUdGRoaitSI1YP5SMuJiLIkUh21qs4DOATg9jgbYeo4s0NNRBSu6mNIRIr1nwsAfhHAyTgbMV+uRFpORJQlYao+LgPwVRHJoRbYn1LVZ+JshMD/6iQvJRIRhQjUqvoigOFuNsKU4WDmg4iIY30QEVnPikBtKpdmGTURkSWBmlUfRERmVgTqAUPP2bSciChLrAjUi4aes2k5EVGWWBGoiYjIjIGaiMhyDNRERJazIlAP5v2bYVpORJQlVkRC3plIRGRmRaAuVxYjLSciyhIrAjUREZlZEahXLs9FWk5ElCVWBOr3LlQjLSciyhIrArUpFc0UNRFRuIkDrDB5bBbjB07hzfky1hYL2LF1I0aHS6n7DCKiqFIRqCePzWLn3hmUK7VUyOx8GTv3zgBAbIE0ic8gImqHFamPVsYPnGoEUEe5UsX4gVOp+gwionakIlC/OV+OtNzWzyAiakcqAvXaYiHScls/g4ioHVYE6lZjfezYuhGFfHNNdSGfw46tG2NrQxKfQZR2k8dmsWX3QVw5tg9bdh/E5LHZXjcpE6y4mPhf7/7X+OxT000TBQxIbTlw8WJeNysykvgM6k9ZqRbq5gX3rKzDdol2YWLCkZERnZqaivSahyZn8OSRM6iqIieC+25eh0dHN8XeNlqKO0n7vMELqJ2JPXb3pr5bh1t2H8SszzWbUrGA58Zua/t9s7QOg4jIUVUd8XvMitTH5LFZfOPIaVTrB42qKr5x5DRPqxLg7CSz82UoLvaSuO7DyVK1ULcuuGdpHbbLikD9X/a8uGR+xEWtLafu4k7SmSxVC3XrgnuW1mG7rAjUP7ngf6+4aTnFhztJZ7JULdStC+5ZWoftsiJQU+9wJ+lMlqqFRodLeOzuTSgVCxDUctNx5JGztA7bZUXVB/XOjq0bfS/kcCcJJ2vVQqPDpdj/tqytw3YwUGccd5LOdSN4ZQ3XYTAGauJOQtShbpe4MlD3SNK1y6yVTh9+Z+mQxMibDNQ9kPSQqhzCNZiNAZHfWXoElbjG9V2x6qMHkq5dZq20WZw3/MQ5Dga/s/RIosSVPeqYhemdJV273KtaaRt7ql5x9Ybi7gGzvj091hYLvrfWx1niyh51jML2zpKuXe5FrXRabk2PKyC26gFH7W2zvj09kqgDZ6COUdjT1W5/sd6gcOs1Q4nfUJCWU/e4AmJQwG/noMWbQNKjWzcCubVMfYjIOgBfA/AhAArgcVX949ha0EfC9M6cdEC5UkVOBFVVlGJMC/idgu85Oot7bizh0Mm5xNIQaTl1j+uGn6DT33bSK6xvT5dul7iGyVFfAPA5VX1BRN4P4KiIPKuq3+taq1KqVa7KG0Srqo2gENeXbAoKh07OtT0UZTu55iTydnEIExDD/P1BAf/BiWnfz2510Gq186fhGgDFo2WgVtWzAM7Wf/4XEXkJQAmAlYG62xtv0Pu36p0lUcYTticbdj21e5EsTbemBwXEsH9/UMAfP3Aq9oMWy/eyJVLVh4hsADAM4IjPYw8AeAAA1q9fH0fbIuv2xuv3/g9OTGPqB2/j0dFNLXtnSaQDwvRkw6wnJ5D7vVeYg0u/nLpHObiaAn43DlpJHPTJHqEDtYi8D8AeANtV9Ufex1X1cQCPA7UZXmJrYQTd3nj93l8BPHH4NEauWNPYUU2flUQ6IExQaLWe/Gbc8ApzcImat7PxVD6Og2scBy3vuvHbjqK2i9IjVKAWkTxqQfoJVd3b3Sb5s6E+2fQ+CoQ6GCSRDggTFFqtJ79A7hV3rtnWU/m4Dq6dXGzyWzeC2nbXabsoHcJUfQiALwN4SVX/qPtNWirsTtztHmunPZl2elbt9DJbBYVW66nV35IfECy8dwFXju2Lredr66l8nAfXds8YTGdy3mBt6zUA6lyYHvUWAP8JwIyITNeX/a6q7u9aqzzC7sRx91i9O9at1wzhicOnO+rJ+AVR0w7crV5mq/VUHMzj3ELF97XFQh7vvneh8XhcbbK1nC+uXHsn32XQmVypWLAqVUTdEabq429RO3j3TNidOM4LWKZ65J+9ag3+7tW3Y+vJBO3A3epltlpPponpi4U8Vq5YhvlycxCPo02mXv6qQh5bdh/saTCKo0a2k+/StG46nf2b0iMVY31ESWl0mgt0gtdA/WYUt3Klitf/uYwvbLs+toteQTuw6QA1W7/bLexnmnrsptefL/v3ps+XK8bHwvZ8TW3x6+XnBwTvvnehcWCwJW/djk7OGNJU6kjdkYpAncSG6nczip8358ux3oUUtAMH5cRNAcsvXbPn6GyoU27ntaaSHefA2O51gDCn/+62L7hSLA5vL9TGShE/nVw/6ZdSR2pfKgJ1EhtqmEoHIHwuOmwACdqB/Q5QDr/TZr9A6JdTD/Nar/yANA6M7R40W53+e79n0wHDObjZWinip9POBmfhybZUBGqg+xtqmFPQsDtWlAAStAM7z90e8hZkU3VAu69tUr9K0clBs9Xpf5j6beDiwdLWShE/7BVTJ6wP1Ft2Hwy8vTmuDd/Us82JYFG143KqoLvZnNf4/R1RbkGOUiER9bWVqjb1fNtZz61O/8Oc1QiAW68ZCmxzrytFTLrV2UhL+ofaZ32gNvVG4z7tNfVs2xmuMGoAabUD+7VNAGz4QKGpImJVIb+kIsNPIZ/DrdcMNb02qCSvVftbcd+OHlT7G+b9FcCeo7MYuWJNagZ+6qY0pX+ofakYj9pvHOO4xzseHY5vTNmgMY7bma5pdLiEe24sNdVIKoDnXn27aYzjd9+7EPg+zt91z40l7Dk62/Tad358AflccBVmcTC/ZNlDkzO4aud+bBjbh6t27sdDkzNNj7vHYnba7XyKdx2vKix9fz/O98wxm9Mz7jd1xvoetcPb2+rGaW+YU1O/00ygOXXhrbQALvZivb2f7RPTeORbJ/Dwx64N/OxDJ+eM+WZHpaoQ8a+Ddtfcbtl9cMnOXVmsvSjnU5bo8C5+aHIGXz98uvF7VbXx+6OjmwCY8+Z+NcASoVrfqb5xPiOrp/1pS/9Qe1ITqL291CROe8OUuu345nFALwa6oIH6TTnYcwsVbJ+Yxq6nT2DXXf4BO+yOp1o7KARVFwS9lylIA0vrq588csb3eU8eOdMI1EG14N4bWeZbpF7cBkQateTOXZzjB07hwfqBT7XW3lWFPESA+YVKXwZypn+yIRWpD3dpmCOJ6ay80yc9cfj00p5oVRtB2lGuVLHvxbNL3rNVsJ0vV4xTNIXd8VYP5lumcNrdib2vMwV193LTZwmwZGoqv9SK81y/z9g+MY3hP/gOHpqcafquzi1UMF+uQFFbp+cWKlbP29gJpn+yIRWB2m9PjTOn7CdKqZufcwuV0IHIzZRf9Nsh/bzz41qe+rmx2/D93XfiubHbfEsCo44JMFB/nVvOkKtwL3cqNLz8arvPLVSWtKuQz+FTm9cbP+vcQsX3AGqSpvxtmOsZ3d4PyA6pSH1UqorPPXUcwNJZNbq1Qcad4ytXqlixbGBJWiLsZzt/566nTwRWdlQWtWUd8ehwyVibbbKIWj23cxFvdLiE+25e15Sjdtx387rGz4dOzkX6HPeocO65JJ/w+Rz3a6LwW7+2lbhFqebgzTD9LxWBGqid6ppmIenGzhV0+7ZbPidNOeog58sVfGHb9XhwYjowuJjSBe587OeeOh54m3srpZB/n5c7YDh56CePnEFVFTkR3HfzusbysG3x8rvYGPb7CKM42DzQU5Tb7JOSppt5qPtEAy4etWtkZESnpqZCP3/D2L5I718KqKyI67Rv8tisMaB6b4IBYLwpxdvu58Zuw5Vj+4yBOj8gGP+P17X8G4LW2erBPAaXLws8gIW9C9Ak7MhtW3Yf9F0vpoHvvZ9hGvK1XQNS+/7cB1ZTW3o5Op1pGxEA3999Z9LNoQSIyFFVHfF9LI2BGjDvXDkRfP6TrQOdI6hXHtQuv3GATUHJ3d5SsYB3f3LBmL7I5wQbPjCIl996t7FsxbIBvHdhsemzrtq5P7BCw2vl8hzyuQGcL1cavchnjp8NdYOM6e/5/u478dDkzJIe9cgVaxrrdFV9/OpK9WJbC/lcoyqm1cEtPyB43yXLML9QQXEwjx9XqihXFttqMwBj+WLQ39gLpm2JQ5v2r74M1EHcgSBqr9LdK4/SG1yeE1SqGipfGiVdYivnrMYvR+01AAACLCqWpEei9pTD5Pjj0sug2GrbpP6TuUAN+E9T5N3Ig3rApWIBGz5QwHOvvh172/rB/ZvXN3rSUQmAT21e3+h5z86XA2+08Yry3LCv9W4v7p58ry4u2naBk7ork4HaxJ33DMoVU/fl62ch7fD2rPMDAggC38850/K7tnHD+lU4/No5VLV2d6egdgbgfg57s9RNQYE6HXXUMXKu6D80OYOBKPcsU+zaDdJOrXCpXh3jXBzMD5i/z5wIHrt7Ex4d3bSk7vieG0t44fT5Rk9btTlIA7WKi+0T06HHZyGKU2rK8+JUrlSNk9SS3bxjdbvzuAuGi4ze3rC37thv7BMTG0r3KHsy16N2MEinh+muuzDjVzs96aCgGrXWO013N1J/yGSPmmplamtXxXcTSbcEVV6ECbBV1cZgTaYLcu3cTMPR6ShJme1RZ51qbTwQ0xgaNmg1uFDYwaW8Y654c8x+46jkc4JiwPjYHJ2OksRAnWFbdh9su8zNT5wxP8zgQmEHqnLzS1v4DWw0/onrMP3wR/DFbddzdDrqOaY+MizutIcq8MVt13d8q7dz16cTUE3B2p2rjvK3+D3XNLARJycgG7BHTbFyeqdBaQPAf4xpZ3mrVIX3854bu61RqheGzekeIj8M1BQbJziPDpewckXwyZp77kSH3635YSssoqRBwqR7nLGgN4ztw4MT05EOHkRxY+qDYjEgwK67rgVQC3JhUhHOIFVOSsH0mjAVFt4URVAo9va+W025Zjp4MP1BSWGgplj81CX5puFIw/CW3pnGXglbYeHOMwcNqOW+EOg3QH+Ym6FYnkdJYuqDYuFMfBvmJhSHt3LCNG2XaXmr9/amQpzBoNw94XanXGN5HiWJPWqKhRO4ovQ0H/nWicaUYMX6bOF+ok7nBYSv1minZ8zyPEoaAzV1zB24otzld27h4qQFQRMYBAXToKFAw8wlaGqv98Km3zyORElh6oM6Uizkm25MaecmlFZMaQYnv9xJRYZfe52Zz903wHxh2/V43TCrO1G3sUdNHVm5YlnjIqLTsy0O5mObhSUozWCaAPaRb50IfYMKb2ihNMjcxAEUv9WDeZwvV5aM4dyOwfwAVq9c0VQqZ5pSLezEDxz0n9Kgo4kDROQrIvKWiHw3/qZRPzi3EE+QBoDly3J4buw2fH/3ndixdSMmnj/TlNrY8c3jjdRG2MoLDktKaRcm9fHnAP4UwNe62xSii2V+QK0qxDsLTKWqeORbJwAA7/7kQuj3Zd0zpVnLHrWq/g0AzvBKsTKNtuHuJburQtzOLVSwc+9MYKVI0PsSpU1sVR8i8oCITInI1Nxc9LpXSo9OhzRaPZjHpzav72j40CgXK1n3TGkXW6BW1cdVdURVR4aGot9JRumhQEcleD+uLGLkijVLxoD2XvBrNQJfGGGm4iKyHcvzqC2P3b0Jn3vqeFsTDzgX91rVJO+661rs+MvjqLiuVOYHBCtXLAuV9mC1B/ULBmpqy+/ufRHLlwnKlaWBWqQ2iYDfsKWOdkbEc8rzALScnCDOOwiD7n4kSkLLQC0iTwK4BcClIvIGgIdV9cvdbhjZbaGyuGTZ6sE8Hv7YtY0gNnls1tjrbmdEPK8HJ6Z9DwTFQt44IW5UfqPrOaMDMlhTUsJUfdynqpepal5VL2eQJhPV5uA1OlzC5z95XVfmHAwKkucjVIO0Yrr7kXXZveNM6nDl2D5s2X0wE5M4MPVBsXHyxt5UwT03lvDM8bONxy/Jx3MNuziY9y3hKw52fhHSYUrRsC67N7J6hsNBmQhAbYYWoJbbvfqDK9t+H7+BkiaeP9N0c4pTB91pT8h0HTPOURFMKRrWZfdGVs9wGKgJALCoQD4n2LF1I16bW2j7ffx2pEpVmyo3gNrOtX1iGhvG9uGqnfvx0GS4WWHcTCmOOFMfptH1WJfdG1k9w2GgpoZKVTF+4FRbJXdA7SJeOztMVRVfP3w6crBOorfrzKoeVO9NycnqGQ4DNTV5c76MnGmqFdRK7kypkY9ed1lHO8yTR85Een5Svd3R4VJjoCiOR91bWT3DYaCmJmuLBdx38zrj4woYUyOHTs5hx9aNyOeaA31uQJAfaH3jedSePHu72ZPV75xVH9TE6Zl84/BpLK2UrjEF1Ebaw/PwAIBtN61rjCttCsdBPXmTMNNtUX/J4nfOHjU1FAt5jA6XMH7glDFIA+aAurZYwPiBU0suHFYWFYdOzjXSB/dvXu/7+qCePFGWMVBnRKu+aiGfw667rgUQfAW9kM/hvpvXGfOEYa7KPzq6CfdvXt8I+DkR3L95PR4d3RTiLyHKHqY+MkLRPJN20BRXppm53SPRjVyxxnf8i/EDp3xf673I+OjoJgZmopAYqDNEUQu2rQYV2rF145JBj7wj0ZnyhKbX9vtVeaJuYqDuI0Gj1Tmqqtg+MY3tE9PGEeY6mZmbs3oTxY+zkKdYPidYuXwZzpcrjYBoSj2YcMxmIjsEzULOHrVFwvSI3Xlmv57q1A/extcPnw79mc44CQzURPZioLZEmCAdZjD8Qyejz1fZ7+MkEKUdA7UlWgXp/ABCDYYfJe3h6PdxEojSjnXUKVFZRKhhQaPe3ceKDCL7MVCnSJgxd4PGyxDU7j5cPZjP1DgJRGnH1EeKhMkllww3q5SKhdjmESSiZLFHnSJhcslZHQaSqJ8xUCfMySF7M8nO76ViAfdvXt92sM3qMJBE/Yypjy4Q8Z+3z31ziXcCWG/ZnWksjTCyOAwkUT9joI6okB8AIEvmBXS4R4FzgvFsfdYU9yScrYIpgy0ROZj6iOieGy9vpBbc/IbqHB0uNXLGTjWGM719pzNwE1F2sEcd0Z6jsxi5Yk3oCoqg6e3ZYyaiMNijjsidvggjq9PbE1F8GKjbECXIZnV6eyKKDwN1G6IEWdY1E1GnmKOOKGqQ5UD6RNQpBuoA+Zxg279ZZ5xbMCyW2hFRJxioXYqFPFauWMaeLxFZhYG6rpDPYddd1zIwE5F1GKgRbuYUIqJe6ZtAvXowj3MLFd/HSsUCbr1mCHuOzjbdfMKJXYkoDfomUD/8sWux45vHUaleHA0pnxOMf+K6RiDuZKAjIqJeCRWoReR2AH8MIAfgS6q6u6utiqhYyIcqg2P1BRGlUctALSI5AH8G4BcBvAHgeRF5WlW/1+3GhZEfEHz0usuwZffBRoD+wrbrGZCJqG+EuTPxJgCvqOprqvoegL8A8PHuNiucAQDbblqHPUdnMTtfhoKj0xFR/wkTqEsAzrh+f6O+rOcuKxZw6OSccXQ6IqJ+ENvFRBF5AMADALB+/fq43jZQ0OBIHJ2OiPpFmB71LIB1rt8vry9roqqPq+qIqo4MDQ3F1b5Aa4sFjk5HRH0vTKB+HsDVInKliCwHcC+Ap7vbrNacwZE4Oh0R9buWqQ9VvSAinwFwALXyvK+o6omut8ylkM/hnhtLgYMjsT6aiPpVqBy1qu4HsL/LbTFqdfcg66OJqJ+lYuIABmEiyjLrA7V3tm8ioqyxPlDzoiARZZ31gZppDyLKOusDNRFR1jFQExFZjoGaiMhyDNRERJZjoCYishwDNRGR5RioiYgsx0BNRGQ5BmoiIssxUBMRWY6BmojIclYE6qs/uDLSciKiLLEiUD/72VuWBOWrP7gSz372lt40iIjIIrHNQt4pBmUiIn9W9KiJiMiMgZqIyHIM1ERElmOgJiKyHAM1EZHlRFXjf1OROQA/aPPllwL4pxib0y1paGca2giwnXFjO+OTZBuvUNUhvwe6Eqg7ISJTqjrS63a0koZ2pqGNANsZN7YzPra0kakPIiLLMVATEVnOxkD9eK8bEFIa2pmGNgJsZ9zYzvhY0UbrctRERNTMxh41ERG5MFATEVmuZ4FaRG4XkVMi8oqIjPk8vkJEJuqPHxGRDQm3b52IHBKR74nICRH5LZ/n3CIi50Vkuv7v95Nso6sdr4vITL0NUz6Pi4j89/q6fFFEbuhBGze61tO0iPxIRLZ7ntOT9SkiXxGRt0Tku65la0TkWRF5uf7/asNrP11/zssi8uketHNcRE7Wv9e/EpGi4bWB20gC7dwlIrOu7/YOw2sD40KX2zjhat/rIjJteG1i67JBVRP/ByAH4FUAHwawHMBxAP/K85zfBPA/6z/fC2Ai4TZeBuCG+s/vB/APPm28BcAzvViHnna8DuDSgMfvAPBtAAJgM4AjPW5vDsA/olbg3/P1CeDnAdwA4LuuZf8NwFj95zEAf+jzujUAXqv/v7r+8+qE2/kRAMvqP/+hXzvDbCMJtHMXgN8OsV0ExoVuttHz+OcB/H6v16Xzr1c96psAvKKqr6nqewD+AsDHPc/5OICv1n/+JoBfEBFJqoGqelZVX6j//C8AXgJQSurzY/ZxAF/TmsMAiiJyWQ/b8wsAXlXVdu9ejZWq/g2Atz2L3dvfVwGM+rx0K4BnVfVtVT0H4FkAtyfZTlX9jqpeqP96GMDl3fr8sAzrM4wwcSEWQW2sx5lPAniyG5/djl4F6hKAM67f38DSINh4Tn1DPA/gA4m0zqOedhkGcMTn4X8rIsdF5Nsicm2yLWtQAN8RkaMi8oDP42HWd5LuhXknsGF9AsCHVPVs/ed/BPAhn+fYtl5/DbUzJz+ttpEkfKaeovmKIZVky/r8dwB+qKovGx5PfF3yYmILIvI+AHsAbFfVH3kefgG10/frAPwJgMmEm+f4OVW9AcAvAfjPIvLzPWpHSyKyHMBdAP7S52Fb1mcTrZ3vWl3HKiK/B+ACgCcMT+n1NvI/AFwF4HoAZ1FLLdjqPgT3phNfl70K1LMA1rl+v7y+zPc5IrIMwCoA/5xI6+pEJI9akH5CVfd6H1fVH6nqO/Wf9wPIi8ilSbax/tmz9f/fAvBXqJ1CuoVZ30n5JQAvqOoPvQ/Ysj7rfuikh+r/v+XzHCvWq4j8CoCPAvhU/aCyRIhtpKtU9YeqWlXVRQD/y/D5PV+f9VhzN4AJ03N6sS57FaifB3C1iFxZ72HdC+Bpz3OeBuBcRf8EgIOmjbAb6nmqLwN4SVX/yPCcn3by5iJyE2rrM+mDyUoReb/zM2oXl77redrTAH65Xv2xGcB512l90oy9FRvWp4t7+/s0gP/j85wDAD4iIqvrp/IfqS9LjIjcDuB3ANylqguG54TZRrrKc03kPxg+P0xc6LZ/D+Ckqr7h92DP1mWSVy49V07vQK2S4lUAv1df9geobXAAcAlqp8evAPh7AB9OuH0/h9rp7osApuv/7gDwGwB+o/6czwA4gdrV6cMAfrYH6/HD9c8/Xm+Lsy7d7RQAf1Zf1zMARnr0na9ELfCuci3r+fpE7cBxFkAFtbzor6N2PeT/AXgZwP8FsKb+3BEAX3K99tfq2+grAH61B+18BbW8rrONOpVSawHsD9pGEm7n/65vey+iFnwv87az/vuSuJBUG+vL/9zZHl3P7dm6dP7xFnIiIsvxYiIRkeUYqImILMdATURkOQZqIiLLMVATEVmOgZqIyHIM1ERElvv/AAECE7lYm/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "\n",
    "#drop zero snowfall measures which is probably the Junes, Julys and Augusts - \n",
    "#look at z score and eliminate anything more than 3 std ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22c939-4c42-4f49-a759-0c59e68aaf2b",
   "metadata": {},
   "source": [
    " This is a scatterplot with the plt.scatter() function, graphing the y_test data against the predictions from our training model. This is still not linear - the single dataset also was not. This, by the way, is what having zero snowfall days looks like along the X axis at 0.0\n",
    "\n",
    "This information is not super useful by itself, but plotting it gives us a better idea of how accurate our predictions (and thus our model) is. The straighter the line, the better the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8df3b29c-af59-498d-b80c-8887790a2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.20006900704046504\n"
     ]
    }
   ],
   "source": [
    "#accuracy score\n",
    "\n",
    "print(\"Score:\", lm.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfabc695-500f-4345-a9b9-83b34ee4ce5c",
   "metadata": {},
   "source": [
    "The accuracy of this model in predicting snowfall on any given day was just 20 % accuracy.  One fifth of the time, our model could accurately predict if it is going to snow on a particular day during the winter months in Sault Ste. Marie, Michigan.  \n",
    "\n",
    "Before the zeroes were removed in our single dataset model it was accurate some 20% of the time, as well. Accuracy took a hit when the model was trying to predict if snow would fall in July, for instance. We had fed it misleading information at first. Removing the zeroes, or summer days, helped the model greatly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55044c8-64d9-4839-bcfe-9373ed5b49fa",
   "metadata": {},
   "source": [
    "# K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc8a43-062f-4eb3-b3e3-6ab19c1cbf35",
   "metadata": {},
   "source": [
    "K-Folds Cross Validation is one method I could try to improve the accuracy of the model - The idea behind k-folds cross validation is that you don’t want to rely on just one iteration of train-test-split, because it could be biased accidentally. So if one is good, isn’t more better? You can create as many iterations of training as you like, with the number of iterations indicated as k. \n",
    "​\n",
    "If you break down k-fold categorization into its most basic components, here is what this function does:\n",
    "​\n",
    "Randomizes the data\n",
    "Splits the data into groups (k #)\n",
    "For each group, creates a test set and a training set, then fits a model and retains the accuracy score\n",
    "Summarizes the model using each iteration’s accuracy score\n",
    "Each separate group of data will the testing data once, and will be used as training data for the remainder of the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad061fff-82a4-4c19-8c53-e935398daa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69703c8c-0d4c-47d3-818e-9352b9b2eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [    0     1     3 ... 64365 64366 64367], test: [    2    10    11 ... 64343 64359 64362]\n",
      "train: [    1     2     5 ... 64365 64366 64367], test: [    0     3     4 ... 64361 64363 64364]\n",
      "train: [    0     2     3 ... 64362 64363 64364], test: [    1     5     9 ... 64365 64366 64367]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits =3, shuffle = True, random_state= 1)\n",
    "for train, test in kfold.split(x,y):\n",
    "    print('train: %s, test: %s' % (train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7049f958-81fd-46eb-a08a-d2a9797fe66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20301172 0.20004393 0.20516632 0.20970501 0.18872883]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lm, x,y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196ff9c-56dd-4fbc-beca-81e80bd6da52",
   "metadata": {},
   "source": [
    "Accuracy is still in the 20s. Using kfold, four of the trained models could accurately predict snowfall just 20% of the time, with the fifth model trailing at 18%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84113771-799e-4fb2-9d44-0caed5e5a8eb",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a2319-c123-4bb3-afef-4275bcb8d833",
   "metadata": {},
   "source": [
    "A decision tree regressor is a more powerful model compared to the linear regression seen above, and perhaps more applicable since that wasn't a linear distribution. The power of decision trees lies within its ability to identify nonlinear relationships within the data.\n",
    "\n",
    "Other tree methods can introduce multicollinearity, meaning that it makes the trees too highly correlated. If we average things that are already a lot alike, we are not reducing variability and instead are introducing bias. But random forests randomizes everything equally and can thus reduce bias and prevent the tree outcomes from overlapping excessively. Random forests are also an awesome choice because there are no assumptions to test for, we don't need to scale any variables, and the model itself doesn't need a lot of playing around to get a good fit right off the bat.\n",
    "However, decision trees are not without their downsides. While decision trees are great for complex datasets, they overfit the data and as a result do not generalize well. This would make is extremely difficult to model and predict something already unpredictable: the weather. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2895b48f-367c-412b-8a30-3895e9d7da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3456ed8-5c58-4094-a304-148e5fcc257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Random Forest Regressor \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100,max_depth= 8,) #accuracy might go down, but fewer errors .important to not overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1e5a2dc-f8fc-49e3-a6dd-cf8d2de94dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model on the weather data \n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ac59109-18bb-4699-b4c4-bfb4b1f3138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this trained model to make predictions on the test data: will it snow? \n",
    "\n",
    "y_pred =  rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c8511c-5874-439d-bd23-a7fbb14f8dd3",
   "metadata": {},
   "source": [
    "When trying to evaluate the performance of a regression model (i.e. a model that predicts continuous values instead of categorical class labels), we can use different evaluation metrics such as mean absolute error, mean squared error, and R-squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df15dfb4-b22d-4307-b41a-e534ea6c8949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.13529706448903486\n",
      "Mean Squared Error: 0.21162885910145068\n",
      "R-squared: 0.7742140145894791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Print the mean absolute error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Print the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Print the R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R-squared:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729705c-ce71-4756-825f-91d7f8498123",
   "metadata": {},
   "source": [
    "### Interpretations of the Random Forest\n",
    "\n",
    "The mean absolute error tells us, on average, how far off our predictions are from the true values. In our case, the mean absolute error is .13, which means that our predictions are, on average, .13 days away from the true values. Thirteen percent of a day is just over 3 hours.\n",
    "The mean squared error tells us how much error there is in our predictions, on average. In our case, the mean squared error is .211, which means that our predictions are, on average, .21 days away from the true values. That's a fifth of a day, or 4.8 hours! \n",
    "The R-squared score tells us how well our predictions match the true values. In our case, the R-squared score is 0.77, which means that our predictions explain 77% of the variation in the true values. This is a good score, as it's over 70%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d0c71e8c-0550-493e-8a4e-27d0b5cb4152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7742140145894791\n"
     ]
    }
   ],
   "source": [
    "print(\"Score:\", rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214133ba-531e-4dba-86c2-3ab65bad9e88",
   "metadata": {},
   "source": [
    "77 % is an acceptable score for this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a79ba-36b4-44de-ac4c-70630225117b",
   "metadata": {},
   "source": [
    "In this machine learning study, the goal was to create a model that could accurately predict whether there would be snowfall on any given day in Sault Ste. Marie, Michigan. Located in the Upper Peninsula of Northern Michigan, Sault Ste. Marie experiences relatively cold weather and snowfall for much of the year, making it an interesting case study for predicting this type of weather.\n",
    "\n",
    "The researcher gathered weather data from a single weather station at Sanderson Field in order to train and test the machine learning models. The dataset contained 70,730 rows with five columns of data, including the date, snowfall amount, maximum temperature, minimum temperature, and average wind speed. The data was split into a training dataset (60% of the data) and a testing dataset (40% of the data) in order to evaluate the performance of the models.\n",
    "\n",
    "Initially, the researcher considered using a linear model, such as a linear regression, to make predictions about snowfall. However, upon examining the data, it was determined that a linear model was not the most appropriate choice for this dataset. This was because the distribution of the data was not linear, meaning that a linear model would not be able to accurately capture the relationships between the features and the target variable (snowfall).\n",
    "\n",
    "To address this issue, the researcher decided to try using a decision tree regressor, which is a more powerful model that is able to handle nonlinear relationships. The decision tree regressor works by constructing a tree-like model of decisions based on the features of the data. At each internal node of the tree, the model makes a decision based on the value of a feature, and then splits the data into two or more branches based on that decision. This process is repeated until the tree is fully grown, and the resulting model is able to make predictions about the target variable by following the branches of the tree.\n",
    "\n",
    "To evaluate the performance of the decision tree regressor model, the researcher used a variety of metrics, including the mean absolute error, mean squared error, and R-squared score. The mean absolute error tells us, on average, how far off our predictions are from the true values. The mean squared error tells us how much error there is in our predictions, on average. The R-squared score tells \n",
    "us how well our predictions match the true values. In our case, the mean absolute error is .13, which means that our predictions are, on average, .13 days away from the true values. Thirteen percent of a day is just over 3 hours. The mean squared error tells us how much error there is in our predictions, on average. In our case, the mean squared error is .211, which means that our predictions are, on average, .21 days away from the true values. That's a fifth of a day, or 4.8 hours! The R-squared score tells us how well our predictions match the true values. In our case, the R-squared score is 0.77, which means that our predictions explain 77% of the variation in the true values. This is a good score, as it's over 70%. \n",
    "\n",
    "In addition to evaluating the performance of the decision tree regressor model using these metrics, the researcher also used k-fold cross validation to further assess the model's accuracy. K-fold cross validation is a technique that involves dividing the data into k folds, training the model on k-1 folds, and then evaluating the model on the remaining fold. This process is repeated k times, with each fold serving as the test set once. The final accuracy of the model is then calculated as the average accuracy across all k iterations.\n",
    "\n",
    "Overall, this study demonstrated that it is possible to create a machine learning model that can accurately predict snowfall in Sault Ste. Marie, Michigan. While the model was not perfect, it was able to achieve a relatively high level of accuracy, and there are several techniques that could be used to further improve its performance. In the future, it would be interesting to see how the model performs when applied to other locations or when trained on a larger and more diverse dataset. I want to explore how I predict if this year it will snow on Christmas? Additionally, it would be interesting to explore the use of other machine learning algorithms and techniques to see if they could lead to even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c300d29-c30f-4456-a9e3-71517c8e355f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
